{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pylsl\n",
    "import numpy as np\n",
    "from pylsl import StreamInlet, resolve_stream                  \n",
    "from nltk import flatten\n",
    "import psutil\n",
    "import dsp\n",
    "\n",
    "from pynput.keyboard import Key, Controller\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "confidence_threshold = 0.15   \n",
    "controller = Controller()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'blue' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "def select_key(dir, ):\n",
    "    \n",
    "    if dir == \"L\":\n",
    "        controller.press(Key.left)\n",
    "        controller.release(Key.left)\n",
    "    elif dir == \"R\":\n",
    "        controller.press(Key.right)\n",
    "        controller.release(Key.right)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "\n",
    "def features(raw_data):\n",
    "\n",
    "    implementation_version = 4 # 4 is latest versions\n",
    "\n",
    "    raw_data = np.array(raw_data)\n",
    "\n",
    "    axes = ['TP9', 'AF7', 'AF8', 'TP10']                        # Axes names.\n",
    "    sampling_freq = 250                                         # Sampling frequency of the data.\n",
    "\n",
    "    #Parameters specific to the spectral analysis DSP block [Default Values].\n",
    "    scale_axes = 1                                             \n",
    "    input_decimation_ratio = 1                                  \n",
    "    filter_type = 'none'                                        \n",
    "    filter_cutoff = 0                                           \n",
    "    filter_order = 0                                            \n",
    "    analysis_type = 'FFT'    \n",
    "    draw_graphs = False                                  \n",
    "\n",
    "    # The following parameters only apply to FFT analysis type.  Even if you choose wavelet analysis, these parameters still need dummy values\n",
    "    fft_length = 64                                             \n",
    "\n",
    "    # Deprecated parameters. Only for backwards compatibility.  \n",
    "    spectral_peaks_count = 0                                    \n",
    "    spectral_peaks_threshold = 0                                \n",
    "    spectral_power_edges = \"0\"                                 \n",
    "\n",
    "    # Current FFT parameters\n",
    "    do_log = True                                               # Log of the spectral powers from the FFT frames\n",
    "    do_fft_overlap = True                                       # Overlap FFT frames by 50%.  If false, no overlap\n",
    "    extra_low_freq = False                                      #Decimate the input window by 10 and perform another FFT on the decimated window.\n",
    "                                                                # This is useful to extract low frequency data.  The features will be appended to the normal FFT features\n",
    "\n",
    "    # These parameters only apply to Wavelet analysis type.  Even if you choose FFT analysis, these parameters still need dummy values\n",
    "    wavelet_level = 2                                           # Level of wavelet decomposition\n",
    "    wavelet = \"rbio3.1\"                                         # Wavelet kernel to use\n",
    "\n",
    "    output = dsp.generate_features(implementation_version, draw_graphs, raw_data, axes, sampling_freq, scale_axes, input_decimation_ratio,\n",
    "                        filter_type, filter_cutoff, filter_order, analysis_type, fft_length, spectral_peaks_count,\n",
    "                        spectral_peaks_threshold, spectral_power_edges, do_log, do_fft_overlap,\n",
    "                        wavelet_level, wavelet, extra_low_freq)\n",
    "\n",
    "\n",
    "    return output[\"features\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the TensorFlow Lite model\n",
    "model_path = \"type the location of your TensorFlow model\"            #This is a placeholder \n",
    "interpreter = tf.lite.Interpreter(model_path=model_path)\n",
    "interpreter.allocate_tensors()\n",
    "input_details = interpreter.get_input_details()\n",
    "output_details = interpreter.get_output_details()\n",
    "\n",
    "print()\n",
    "print(input_details)\n",
    "print()\n",
    "print(output_details)\n",
    "\n",
    "# Connect to the LSL stream\n",
    "streams = resolve_stream('type', 'EEG')                         # create a new inlet to read # from the stream\n",
    "inlet = pylsl.stream_inlet(streams[0])\n",
    "\n",
    "nr_samples = 1\n",
    "\n",
    "\n",
    "while \"tuxracer.exe\" in (i.name() for i in psutil.process_iter()): # check if tuxracer program is running only continue if it is\n",
    "\n",
    "    back_nr = left_nr = right_nr = 0\n",
    "    \n",
    "    for iter in range (nr_samples):\n",
    "        all_samples = []\n",
    "        for i in range (2000 // 4):                                                 # 2000 ms = 2 secs, 4 EEG-electrodes (channels)\n",
    "            sample, timestamp = inlet.pull_sample()\n",
    "            sample.pop()\n",
    "            all_samples.append(sample)\n",
    "\n",
    "        all_samples = flatten(all_samples)                                          \n",
    "        all_samples = features(all_samples)\n",
    "\n",
    "        input_samples = np.array(all_samples[:65], dtype=np.float32)\n",
    "        input_samples = np.expand_dims(input_samples, axis=0)\n",
    "\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_samples)            # input_details[0]['index'] = the index which accepts the input\n",
    "        interpreter.invoke()                                                        # run the inference\n",
    "\n",
    "        output_data = interpreter.get_tensor(output_details[0]['index'])            # output_details[0]['index'] = the index which provides the input\n",
    "\n",
    "        background  = output_data[0][0]\n",
    "        right       = output_data[0][1]\n",
    "        left        = output_data[0][2]\n",
    "        \n",
    "        if left >= confidence_threshold:\n",
    "            predicted_key = \"L\"  # Adjust based on your model's output mapping\n",
    "            select_key(predicted_key)\n",
    "        elif right >= confidence_threshold:\n",
    "            predicted_key = \"R\"  # Adjust based on your model's output mapping\n",
    "            select_key(predicted_key)\n",
    "\n",
    "    #print(f\"Left: {left:.8f}  Background: {background:.8f}  Right: {right:.8f} Blink: {blink:.8f}\")       # this is used to show the confidence level of each brain activity.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
